{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modèles de langage *ngram* avec NLTK\n",
    "\n",
    "Je vous invite à lire le notebook de Yoav Goldberg [ici](http://nbviewer.jupyter.org/gist/yoavg/d76121dfde2618422139) ainsi que l'article de blog « The Unreasonable Effectiveness of Recurrent Neural Networks » [ici](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) auquel il fait référence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraînement\n",
    "\n",
    "Pour l'entraînement (ou apprentissage) nous allons utiliser des données issues de 52 articles du journal Le Monde publiés en 2016 dans la rubrique 'Pixels'. Le fichier ``data.txt.tag`` contient le contenu textuel de ces articles étiqueté avec TreeTagger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Liste de mots\n",
    "\n",
    "Génération d'une liste de mots (tokens) à partir du fichier ``data.txt.tag``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random\n",
    "\n",
    "def word_list(file):\n",
    "    \"\"\"\n",
    "    Extrait la liste des tokens d'un fichier TreeTagger (passage en minuscule)\n",
    "    Args:\n",
    "        file (str): fichier TreeTagger\n",
    "    Returns:\n",
    "        list: la liste des tokens\n",
    "    \"\"\"\n",
    "    words = list()\n",
    "    with open(file) as f:\n",
    "        for line in f:\n",
    "            line = line.rstrip()\n",
    "            if len(line.split('\\t')) == 3:\n",
    "                token, tag, lemma = line.split('\\t')\n",
    "                words.append(token.lower())\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95115\n"
     ]
    }
   ],
   "source": [
    "words = word_list('data.txt.tag')\n",
    "print(len(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entraînement d'un modèle bigram\n",
    "\n",
    "Nous allons nous appuyer sur la fonction ``nltk.bigrams`` pour générer la liste des bigrammes possibles de notre liste de mots.  \n",
    "Il faut d'abord calculer la fréquence de ces bigrammes avant de calculer leur probabilité qui nous donnera notre modèle de langage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfreq_2gram = nltk.ConditionalFreqDist(nltk.bigrams(words))\n",
    "cfreq_2gram['il']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cprob_2gram_mle = nltk.ConditionalProbDist(cfreq_2gram, nltk.MLEProbDist)\n",
    "cprob_2gram_mle['il'].prob('machin')\n",
    "cprob_2gram_mle['il'].samples()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cprob_2gram_laplace = nltk.ConditionalProbDist(cfreq_2gram, nltk.LaplaceProbDist)\n",
    "cprob_2gram_laplace['il'].samples()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entraînement d'un modèle trigram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction ``nltk.trigrams`` renvoie une liste de tuples à trois éléments. Cette structure ne peut pas être utilisée directement par le constructeur de la classe nltk.ConditionalFreqDist.  \n",
    "Pour le modèle trigram on doit simplement ajouter une petite étape pour produire la structure de données attendue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigrams = nltk.trigrams(words)\n",
    "cfreq_3gram = nltk.ConditionalFreqDist(((w1, w2), w3) for w1, w2, w3 in trigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfreq_3gram[('de', 'la')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pour'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cprob_3gram_laplace = nltk.ConditionalProbDist(cfreq_3gram, nltk.LaplaceProbDist)\n",
    "cprob_3gram_laplace[('sur', 'moi')].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Génération de texte avec modèle ngram\n",
    "\n",
    "L'idée ici est de se servir du modèle ngram pour générer un texte à partir d'une amorce.  \n",
    "Sans aucune structure syntaxique donc, rien d'autre qu'un modèle trigram appris 95 000 mots. Est-ce que cela va fonctionner ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(history, model, size=100):\n",
    "    history_words = history.split(' ')\n",
    "    for i in range(size):\n",
    "        next_word = model[(history_words[-2], history_words[-1])].max()\n",
    "        history_words.append(next_word)\n",
    "    return \" \".join(history_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"C'était sans compter sur la présence de députés et trois ministres – intérieur , bernard cazeneuve a aussi rappelé l’ omniprésence des attaques purement criminelles . dans un communiqué . utilisé par des pirates , qui a été piraté par l' armée électronique syrienne , elle a\""
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(\"C'était sans compter sur la présence de\", cprob_3gram_laplace, 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ça fonctionne à peu près. Enfin ça fait illusion plutôt, on peut facilement mettre à défaut le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"c'est de la nsa , et de la nsa , et de la nsa , et de la nsa , et de la nsa , et de la nsa , et de la nsa , et de la nsa , et de la\""
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(\"c'est de la\", cprob_3gram_laplace, 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une des parades serait de ne pas sélectionner le mot le plus probable mais d'en piocher un parmi les n plus probables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rand_nbest(hist, model, n):\n",
    "    \"\"\"\n",
    "    Returns a random word among the n bests according to the model\n",
    "    Args:\n",
    "        hist (tuple): the words preceding (tuple of 2 words for a 3gram model)\n",
    "        model (ConditionalFreqDist): ngram model\n",
    "        n (int): n best words\n",
    "    Returns:\n",
    "        str\n",
    "    \"\"\"\n",
    "    bests = sorted(model[hist].samples(), key=lambda sample: model[hist].prob(sample), reverse=True)\n",
    "    if len(bests) > n:\n",
    "        n_best = bests[:n]\n",
    "        word = n_best[random.randint(0, n-1)]\n",
    "    else:\n",
    "        n_best = bests\n",
    "        word = n_best[random.randint(0, (len(n_best)-1))]\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'loi'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_rand_nbest(('de', 'la'), cprob_3gram_laplace, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(history, model, size=100):\n",
    "    history_words = history.split(' ')\n",
    "    for i in range(size):\n",
    "        next_word = get_rand_nbest((history_words[-2], history_words[-1]), model, 15)\n",
    "        history_words.append(next_word)\n",
    "    return \" \".join(history_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"c'est de la société civile » . la motion , qui a travaillé à ajouter la reconnaissance de caractère à un « s » après un article lui avait valu de vivre des expériences qui semblent n' avoir jamais été publiés ailleurs ,\""
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(\"c'est de la\", cprob_3gram_laplace, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"C'était sans compter sur la présence de députés et de ce dernier lui est demandé pourquoi il a bien fallu se construire . fuyant l’ empire ottoman et le drapeau syriens , accompagnés d' une procédure disciplinaire de l' assemblée nationale à partir du destin de ces\""
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(\"C'était sans compter sur la présence de\", cprob_3gram_laplace, 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C'est mieux ce n'est pas encore tout à fait satisfaisant. Quelles pistes pourrait-on tester pour améliorer notre génération de texte ?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
